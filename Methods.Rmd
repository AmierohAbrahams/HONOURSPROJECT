---
title: "Methods"
author: "Amieroh Abrahams"
date: "7 May 2018"
output:
  word_document:
    toc: yes
  html_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 5
    highlight: default
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: yes
  pdf_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    highlight: zenburn
    latex_engine: xelatex
mainfont: PT Serif
monofont: PT Mono
language: Australian
sansfont: PT Sans
fontsize: 12pt
---

## Methods


First I need to find, install and load various packages. These packages will be available on CRAN and can be accessed and installed in the usual way.
```{r prelim-opts, echo=FALSE}
knitr::opts_chunk$set(
  comment = "R>", 
  warning = FALSE, 
  message = FALSE
)
```


```{r setup, include=FALSE}
library(tidyverse)
library(ggpubr)
library(zoo)
library(lubridate)
library(ggpubr)
library(ggrepel)
library(FNN)
library(stringr)

```

Now to get to the data. The first step involves the loading of the site list. 
```{r setup, include=FALSE}
load("site_list_v4.2.RData")
```

Performing the k-means clustering on a data matrix using the kmeans() function of the FNN package. This aims to partition the points into k groups such that the sum of squares from points to the assigned cluster centres is minimized.  At the minimum, all cluster centres are at the mean of the set of data points which are nearest to the cluster centre.  K means clustering using the multiple random seeds finds a number of k-means clusting solutions using R's kmeans function, and selects as the final solution the one that has the minimum total within-cluster sum of squared distances. K-Means attempts to minimize distortion. The data contain variables from many sites along the South African coast, but in the analysis I use only some of them. These variables are the mean, min and max.
```{r setup, include=FALSE}
set.seed(10)
kmeans(site_list[,c(15, 18, 19)], 3)$cluster
clust_columns <- site_list[,c(15, 18:19)]
```


Visualisation of the clusters. My plotting functions partition the data into the clusters and colour code each point accordingly so I can see patterns that exist
```{r setup, include=FALSE}
clust_i <- function(i) {
  set.seed(10)
  ggplot(data = site_list, 
         aes(x = lon, y = lat, 
             colour = as.factor(kmeans(clust_columns, i)$cluster))) +
    borders() +
    geom_point() +
    labs(colour = "cluster") +
    coord_equal(xlim = c(15, 35), ylim = c(-37, -27)) +
    ggtitle(paste0("clust = ", i))
}

clust_6 <- clust_i(6)
clust_5 <- clust_i(5)
clust_4 <- clust_i(4)
clust_3 <- clust_i(3)

clusters <- ggarrange(clust_6, clust_5, clust_4, clust_3, common.legend = T)
clusters
```

It is now nescessary to load the SACTN dataset. The SACTN dataset comprise of 129 *in situ* coastal seawater temperatures derived from daily measurements over up to 40 years. Clustering the sites using the k-means results
```{r setup, include=FALSE}
load("SACTN_data/SACTN_daily_v4.2.RData")
```

Creating a cluster index whilst only selecting cluster 4. Working with three decades of data for each of the sites along the coast. This allows for a longer time series
```{r setup, include=FALSE}
set.seed(10)
site_list$cluster <- as.factor(kmeans(site_list[,c(15, 18:19)], 4)$cluster)

SACTN_daily_clusters <- left_join(SACTN_daily_v4.2, site_list[,c(4, 13, 21)]) %>% 
  filter(length >= 3650 * 3) 
```


The function droplevels is used here to drop unused levels from the factor such as the length column. The unique function is then used to determine the amount sites found within this cluster. 
```{r setup, include=FALSE}
SACTN_clust_1 <- SACTN_daily_clusters %>% 
  filter(cluster == 1) %>% 
  select(-length) %>% 
  droplevels()
length(unique(SACTN_clust_1$index))

```

Creating a function matching the sites 
```{r setup, include=FALSE}
clust_match <- function(df){
SACTN_clust_1_match <- data.frame()
  for (i in 1:length(levels(SACTN_clust_1$index))) {
    # for (i in 1:10) {
    SACTN_df_1 <- filter(SACTN_clust_1, index == levels(index)[i])
    for (j in 1:length(levels(SACTN_clust_1$index))) {
      # for(j in 1:10) {
      if (i == j) {
        next
      }
      if (j < i) {
        next
      }
      SACTN_df_2 <- filter(SACTN_clust_1, index == levels(index)[j])
      SACTN_df_3 <-
        left_join(SACTN_df_1, SACTN_df_2, by = "date") %>%
        na.trim() %>%
        select(date,
               index.x,
               temp.x,
               index.y,
               temp.y,
               -cluster.x,
               -cluster.y) %>%
        rename(
          index_1 = index.x,
          temp_1 = temp.x,
          index_2 = index.y,
          temp_2 = temp.y
        ) %>%
        mutate(index_pair = paste0(index_1, " - ", index_2))
      SACTN_clust_1_match <- rbind(SACTN_clust_1_match, SACTN_df_3)
    }
  }
}
```

I calculated the monthly mean temperature and standard deviation for each year and site found in cluster 1. Consequently we have a data frame with 5 columns and a row for each of months per year. 
```{r setup, include=FALSE}
SACTN_clust_1_legit <- SACTN_clust_1_match %>% 
  mutate(temp_legit = temp_1-temp_2,
         month = month(date, abbr = T, label = T),
         year = year(date)) %>% 
  select(-temp_1, -temp_2) %>% 
  group_by(index_pair, month, year) %>% 
  summarise(temp_mean_month_year = mean(temp_legit, na.rm = T),
            temp_sd_month_year = sd(temp_legit, na.rm = T))
```


The code below lets us visualise the temperature variation at each of the sites found in cluster 1
```{r setup, include=FALSE}
ggplot(data = SACTN_clust_1_match, aes(x = index_pair)) +
  geom_boxplot(aes(y = temp_1), fill = "khaki4", alpha = 0.3) +
  geom_boxplot(aes(y = temp_2), fill = "chartreuse3", alpha = 0.3) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Now I make a visualisation to reveal the relationship between the mean temperature for each month of each year for eacch of the sites in cluster 1.
```{r setup, include=FALSE}
SACTN_clust_1_legit %>% 
  ggplot(aes(x = year, y = temp_mean_month_year)) +
  geom_line(aes(group = index_pair, colour = index_pair), alpha = 0.7, show.legend = F) +
  geom_smooth(method = "gam", se = F, aes(colour = index_pair), show.legend = T)  +
  facet_wrap(~month) + 
  theme_pubclean()
```

Creating a function which allows me to load all the wave data
```{r}
test_func <- function(wave_files){
  site_type <- sapply(strsplit(as.character(wave_files), "/"), "[[", 3)
  site_num <- sapply(strsplit(as.character(wave_files), "/"), "[[", 4)
  site_num <- sapply(strsplit(site_num, ".txt"), "[[", 1)
  site_name <- paste(site_type, site_num, sep = "")

  try1 <- read.csv(wave_files, col.names = c("date", "hs", "tp", "dir", "dirw", "spw"), sep = "", header = F) %>%
    filter(tp != -999) %>% 
    mutate(date = as.POSIXct(as.character(date), "%Y%m%d%H%M", tz = "Africa/Johannesburg")) %>%
    mutate(site = site_name) %>%
    select(site, everything())
  return(try1)
}
```

Now splitting the wave data into the different depths either a depth of 7m or a depth of 15m
```{r}
sites_complete_7 <- sites_complete %>% 
  filter(depth == "wave_7")

sites_complete_15 <- sites_complete %>% 
  filter(depth == "wave_15")
```

Using the FNN package to deetermine the nearest wave data for each of the SACTN sites present in this cluster. Once that was determined only waves minimised to only include the 7 and 15m depths
```{r}
waves_idx_7 <- as.data.frame(knnx.index( as.matrix(sites_complete_7[,2:3]), as.matrix(site_list_30_years[,5:6]), k = 1)) 
waves_idx_15 <- as.data.frame(knnx.index( as.matrix(sites_complete_15[,2:3]), as.matrix(site_list_30_years[,5:6]), k = 1)) 

sites_complete_subset_7 <- sites_complete_7[as.matrix(waves_idx_7),]
sites_complete_subset_15 <- sites_complete_15[as.matrix(waves_idx_15),]

```

Creating a function using the haversine formula to calculate the geodesic distance between two points specified by radian lat/lon. 
```{r}
deg2rad <- function(deg) return(deg*pi/180)
gcd.hf <- function(long1, lat1, long2, lat2) {
  R <- 6371 
  delta.long <- (long2 - long1)
  delta.lat <- (lat2 - lat1)
  a <- sin(delta.lat/2)^2 + cos(lat1) * cos(lat2) * sin(delta.long/2)^2
  c <- 2 * asin(min(1,sqrt(a)))
  d <- R * c
  return(d) 
}
```

Creating a function to calculate matrix of distances between each two sites following the haversine formula
```{r}
CalcDists <- function(latlongs) {
  name <- list(rownames(latlongs), rownames(latlongs))
  n <- nrow(latlongs)
  z <- matrix(0, n, n, dimnames = name)
  for (i in 1:n) {
    for (j in 1:n) z[i, j] <- gcd.hf(long1 = latlongs[i, 1],
                                     lat1 = latlongs[i, 2], long2 = latlongs[j, 1], lat2 = latlongs[j,2])
  }
  z <- as.dist(z)
  return(z)
}
```

After the sites were matched the distance was converted to radians the siteswere matched with the sites of the 30year time series. Hereafter the wave data was combined with the temperature data at a depth of 7 and 15m respectivley. 
```{r}
site_list_match_dist <- site_list_match %>% 
  mutate(lon1 = deg2rad(lon1),
         lat1 = deg2rad(lat1),
         lon2 = deg2rad(lon2),
         lat2 = deg2rad(lat2),
         dist = NA)

# Creating a loop for dstances
for(i in 1:nrow(site_list_match_dist)){
  dist <- gcd.hf(site_list_match_dist$lon1[i], site_list_match_dist$lat1[i], 
                 site_list_match_dist$lon2[i], site_list_match_dist$lat2[i])
  site_list_match_dist$dist[i] <- dist
}

site_list_30_years <- left_join(site_list_30_years, site_list_match_dist[, c(1, 8:10)])

SACTN_daily_clusters_7 <- left_join(SACTN_daily_clusters, site_list_30_years[, c(4, 22)]) %>% 

SACTN_daily_clusters_15 <- left_join(SACTN_daily_clusters, site_list_30_years[, c(4, 23)]) %>% 
  left_join(wave_daily, by = c("date", "wave_15" = "site_wave"))

SACTN_daily_clusters_7 %>%
  group_by(index) %>%
  summarise(temp_dir_cor = cor(temp, dir_mean))

ggplot(data = SACTN_daily_clusters_7, aes(x = temp, y = dir_mean)) +
  geom_line() +
  facet_wrap(~index)

```










